{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Excercise-3-Improve MNIST with convolutions.ipynb",
      "provenance": []
    },
    "coursera": {
      "course_slug": "introduction-tensorflow",
      "graded_item_id": "ml06H",
      "launcher_item_id": "hQF8A"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjHqsmTAVLU"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "# **Improving Computer Vision Accuracy using Convolutions**\n",
        "\n",
        "We saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers --\n",
        ",  \n",
        "\n",
        "1.   the input layer (in the shape of the data)\n",
        "2.   the output layer (in the shapeof the desired output)\n",
        "3.   hidden layer\n",
        "\n",
        "And we experimented with the impact of different sizes of hidden layer, number of training epochs etc on the final accuracy. Our accuracy was about 89% on training and 87% on validation...It is not bad but is it possible to make that even better? One way is  using Convolutions Neural Networks (CNN).In short, with kernel we can take an array (usually 3x3 or 5x5) and pass it over the image. The concept of Convolutional Neural Networks, adding some layers to do convolution before we have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tPCCWo3HIH4"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHQZ8dKzAztQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from os import path, getcwd, chdir\n",
        "\n",
        "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
        "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
        "# and place it inside a local folder and edit the path to that location\n",
        "path = f\"{getcwd()}/../tmp2/mnist.npz\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od6u99zpHT5b"
      },
      "source": [
        "The parameters are:\r\n",
        "\r\n",
        "The number of convolutions we want to generate. Purely arbitrary, but good to start with something in the order of 32\r\n",
        "The size of the Convolution, in this case a 3x3 grid\r\n",
        "The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\r\n",
        "In the first layer, the shape of the input data.\r\n",
        "We'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convolution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. The idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfOhZC3AztW",
        "scrolled": true
      },
      "source": [
        "def train_mnist_conv():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "    training_images=training_images / 255.0\n",
        "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "    test_images=test_images/255.0\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
        "    #model.fit(training_images, training_labels, epochs=10)\n",
        "    #test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    #print(test_acc)\n",
        "    \n",
        "    history = model.fit(training_images, training_labels, epochs=10)\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    \n",
        "    # model fitting\n",
        "    return history.epoch, history.history['accuracy'][-1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKnY55lpAztX",
        "outputId": "ff51c607-fd54-4697-b4ab-f57259ce574b"
      },
      "source": [
        "train_mnist_conv()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3145 - accuracy: 0.9063\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0545 - accuracy: 0.9839\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0337 - accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0221 - accuracy: 0.9927\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0126 - accuracy: 0.9961\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0101 - accuracy: 0.9970\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0076 - accuracy: 0.9977\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0048 - accuracy: 0.9985\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0046 - accuracy: 0.9984\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0046 - accuracy: 0.9985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.9982500076293945)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vSGcaxlHnBb"
      },
      "source": [
        "# **Evaluation**\r\n",
        "Using Convolutions we could improve the accuracy from %87 to 99.8%. We used a single convolutional layer and a single MaxPooling 2D with 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djhp_abbBM9L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}